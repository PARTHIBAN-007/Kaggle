{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kparthiban007/loss-functions?scriptVersionId=218053288\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"32ed1173","metadata":{"papermill":{"duration":0.005483,"end_time":"2025-01-17T13:02:37.647982","exception":false,"start_time":"2025-01-17T13:02:37.642499","status":"completed"},"tags":[]},"source":["# Loss Functions\n"]},{"cell_type":"markdown","id":"f80203df","metadata":{"papermill":{"duration":0.004426,"end_time":"2025-01-17T13:02:37.657369","exception":false,"start_time":"2025-01-17T13:02:37.652943","status":"completed"},"tags":[]},"source":["**Loss Functions are used to validate the model's predicted values and the actual values . By using the values of Loss functions the model's Performance is improved in Further iterations or epochs**\n","\n","**Loss functions are mostly classified into  2 types:**\n","\n","$$Regression Loss$$\n","\n","$$Classification Loss$$\n"]},{"cell_type":"code","execution_count":1,"id":"7952e0f6","metadata":{"execution":{"iopub.execute_input":"2025-01-17T13:02:37.669298Z","iopub.status.busy":"2025-01-17T13:02:37.668729Z","iopub.status.idle":"2025-01-17T13:02:37.679489Z","shell.execute_reply":"2025-01-17T13:02:37.678362Z"},"papermill":{"duration":0.02006,"end_time":"2025-01-17T13:02:37.682337","exception":false,"start_time":"2025-01-17T13:02:37.662277","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","id":"4bb6e658","metadata":{"papermill":{"duration":0.004456,"end_time":"2025-01-17T13:02:37.691798","exception":false,"start_time":"2025-01-17T13:02:37.687342","status":"completed"},"tags":[]},"source":["## Regression Loss"]},{"cell_type":"markdown","id":"74ccc4d8","metadata":{"papermill":{"duration":0.004566,"end_time":"2025-01-17T13:02:37.70116","exception":false,"start_time":"2025-01-17T13:02:37.696594","status":"completed"},"tags":[]},"source":["**Major Loss Functions in Regression Loss:**\n","\n","$$ Mean Squared Errror$$\n","\n","$$ Mean Absolute Error$$\n","\n","$$ Huber Loss$$"]},{"cell_type":"markdown","id":"05240def","metadata":{"papermill":{"duration":0.004416,"end_time":"2025-01-17T13:02:37.710647","exception":false,"start_time":"2025-01-17T13:02:37.706231","status":"completed"},"tags":[]},"source":["### Mean Squared Error"]},{"cell_type":"markdown","id":"8a62c21a","metadata":{"papermill":{"duration":0.004272,"end_time":"2025-01-17T13:02:37.71951","exception":false,"start_time":"2025-01-17T13:02:37.715238","status":"completed"},"tags":[]},"source":["$$\n","\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n","$$\n","\n","$$\n","\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n","$$\n","\n","$ \\textbf{Where:} $\n","\n","   $ n : $ Number of data points.\n","   \n","   $  y_i $ : Actual (true) value for the $_i$th data point. \n","   \n","   $ \\hat{y}_i $ : Predicted value for the $_i$th data point. \n","   \n","   $ (y_i - \\hat{y}_i)^2 $:  Squared difference between the actual and predicted value. \n"]},{"cell_type":"code","execution_count":2,"id":"a7ee1182","metadata":{"execution":{"iopub.execute_input":"2025-01-17T13:02:37.730467Z","iopub.status.busy":"2025-01-17T13:02:37.730049Z","iopub.status.idle":"2025-01-17T13:02:37.741179Z","shell.execute_reply":"2025-01-17T13:02:37.739984Z"},"papermill":{"duration":0.019185,"end_time":"2025-01-17T13:02:37.743389","exception":false,"start_time":"2025-01-17T13:02:37.724204","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["1.3333333333333333"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["def mean_squared_error(y_true,y_pred):\n","    return np.mean((y_true-y_pred )** 2)\n","y_true = np.array([1,2,3])\n","y_pred = np.array([1,2,5])\n","mean_squared_error(y_true,y_pred)"]},{"cell_type":"markdown","id":"30ed2115","metadata":{"papermill":{"duration":0.004738,"end_time":"2025-01-17T13:02:37.753019","exception":false,"start_time":"2025-01-17T13:02:37.748281","status":"completed"},"tags":[]},"source":["### Mean Absolute Error"]},{"cell_type":"markdown","id":"9d00106a","metadata":{"papermill":{"duration":0.004485,"end_time":"2025-01-17T13:02:37.762204","exception":false,"start_time":"2025-01-17T13:02:37.757719","status":"completed"},"tags":[]},"source":["$$\n","\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n","$$\n"]},{"cell_type":"code","execution_count":3,"id":"7c681ac0","metadata":{"execution":{"iopub.execute_input":"2025-01-17T13:02:37.773615Z","iopub.status.busy":"2025-01-17T13:02:37.773248Z","iopub.status.idle":"2025-01-17T13:02:37.7827Z","shell.execute_reply":"2025-01-17T13:02:37.781641Z"},"papermill":{"duration":0.017689,"end_time":"2025-01-17T13:02:37.784908","exception":false,"start_time":"2025-01-17T13:02:37.767219","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0.6666666666666666"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["def mean_absolute_error(y_true ,y_pred):\n","    return np.mean(np.abs(y_true-y_pred))\n","y_true = np.array([1,2,3])\n","y_pred = np.array([1,2,5])\n","mean_absolute_error(y_true,y_pred)\n","\n"]},{"cell_type":"markdown","id":"a03b8148","metadata":{"papermill":{"duration":0.004616,"end_time":"2025-01-17T13:02:37.794485","exception":false,"start_time":"2025-01-17T13:02:37.789869","status":"completed"},"tags":[]},"source":["$\\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 }$\n"]},{"cell_type":"markdown","id":"e64f6369","metadata":{"papermill":{"duration":0.004546,"end_time":"2025-01-17T13:02:37.803895","exception":false,"start_time":"2025-01-17T13:02:37.799349","status":"completed"},"tags":[]},"source":["$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$"]},{"cell_type":"markdown","id":"fdec0ec6","metadata":{"papermill":{"duration":0.00473,"end_time":"2025-01-17T13:02:37.813389","exception":false,"start_time":"2025-01-17T13:02:37.808659","status":"completed"},"tags":[]},"source":["$\\text{Adjusted } R^2 = 1 - \\left(1 - R^2\\right) \\frac{n - 1}{n - p - 1}$"]},{"cell_type":"markdown","id":"0901fde6","metadata":{"papermill":{"duration":0.004511,"end_time":"2025-01-17T13:02:37.822787","exception":false,"start_time":"2025-01-17T13:02:37.818276","status":"completed"},"tags":[]},"source":["### Huber Loss"]},{"cell_type":"markdown","id":"ff04d4f5","metadata":{"papermill":{"duration":0.004475,"end_time":"2025-01-17T13:02:37.831984","exception":false,"start_time":"2025-01-17T13:02:37.827509","status":"completed"},"tags":[]},"source":["\n","$$\n","L_{\\delta}(a) =\n","\\begin{cases}\n","\\frac{1}{2} a^2 & \\text{for } |a| \\leq \\delta \\\\\n","\\delta (|a| - \\frac{1}{2} \\delta) & \\text{otherwise}\n","\\end{cases}\n","$$\n","\n","where \n","$\n","a = y_i - \\hat{y}_i\n","$\n","and \n","$\n","\\delta\n","$\n","is a threshold parameter.\n"]},{"cell_type":"code","execution_count":4,"id":"e7d22c8e","metadata":{"execution":{"iopub.execute_input":"2025-01-17T13:02:37.843273Z","iopub.status.busy":"2025-01-17T13:02:37.842868Z","iopub.status.idle":"2025-01-17T13:02:37.853322Z","shell.execute_reply":"2025-01-17T13:02:37.852204Z"},"papermill":{"duration":0.018602,"end_time":"2025-01-17T13:02:37.855386","exception":false,"start_time":"2025-01-17T13:02:37.836784","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0.5"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["def huber_loss(y_true ,y_pred,delta =1.0):\n","    error = y_true -y_pred\n","    threshold = np.abs(error)<=delta\n","    squared_error =0.5 * np.square(error)\n","    linear_error = delta * (np.abs(error) - 0.5 *delta)\n","    return np.where(threshold,squared_error,linear_error).mean()\n","y_true = np.array([1,2,3])\n","y_pred = np.array([1,2,5])\n","huber_loss(y_true,y_pred)\n","\n","    "]},{"cell_type":"markdown","id":"35eaa1db","metadata":{"papermill":{"duration":0.004757,"end_time":"2025-01-17T13:02:37.865202","exception":false,"start_time":"2025-01-17T13:02:37.860445","status":"completed"},"tags":[]},"source":["## Classification Loss"]},{"cell_type":"markdown","id":"53846406","metadata":{"papermill":{"duration":0.00465,"end_time":"2025-01-17T13:02:37.87505","exception":false,"start_time":"2025-01-17T13:02:37.8704","status":"completed"},"tags":[]},"source":["**Major Loss Functions in Classification Loss:**\n","\n","$$ log loss  Or binary cross-Entropy $$\n","\n","$$ categorical Cross Entropy $$\n","\n","$$ Sparse Categorical Cross Entropy $$"]},{"cell_type":"markdown","id":"ecb07401","metadata":{"papermill":{"duration":0.004675,"end_time":"2025-01-17T13:02:37.884698","exception":false,"start_time":"2025-01-17T13:02:37.880023","status":"completed"},"tags":[]},"source":["### Binary Cross Entropy"]},{"cell_type":"markdown","id":"99926a83","metadata":{"papermill":{"duration":0.00462,"end_time":"2025-01-17T13:02:37.894596","exception":false,"start_time":"2025-01-17T13:02:37.889976","status":"completed"},"tags":[]},"source":["$$\n","\\text{Binary Crossentropy} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n","$$\n"]},{"cell_type":"code","execution_count":5,"id":"c7b642d7","metadata":{"execution":{"iopub.execute_input":"2025-01-17T13:02:37.906863Z","iopub.status.busy":"2025-01-17T13:02:37.905798Z","iopub.status.idle":"2025-01-17T13:02:37.914356Z","shell.execute_reply":"2025-01-17T13:02:37.913368Z"},"papermill":{"duration":0.016971,"end_time":"2025-01-17T13:02:37.916385","exception":false,"start_time":"2025-01-17T13:02:37.899414","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["-92.10553597957568"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["def binary_cross_entropy(y_true ,y_pred):\n","    y_pred = np.clip(y_pred , 1e-15 ,1-1e-15)\n","    return -np.mean(y_true*np.log(y_pred) + (1-y_true)* np.log(1-y_pred))\n","y_true = np.array([1,7,3])\n","y_pred = np.array([1,2,5])\n","binary_cross_entropy(y_true,y_pred)\n","    "]},{"cell_type":"markdown","id":"294035ac","metadata":{"papermill":{"duration":0.004882,"end_time":"2025-01-17T13:02:37.926956","exception":false,"start_time":"2025-01-17T13:02:37.922074","status":"completed"},"tags":[]},"source":["### Categorical Cross Entropy"]},{"cell_type":"markdown","id":"95c31ccf","metadata":{"papermill":{"duration":0.004707,"end_time":"2025-01-17T13:02:37.936762","exception":false,"start_time":"2025-01-17T13:02:37.932055","status":"completed"},"tags":[]},"source":["$$\n","\\text{Categorical Crossentropy} = - \\frac{1}{n} \\sum_{i=1}^n \\sum_{c=1}^C y_{i,c} \\log(\\hat{y}_{i,c})\n","$$\n","\n","\n","where \n","$\n","y_{i,c}\n","$\n","is 1 if the true label for sample \n","$\n","i\n","$\n","is class \n","$\n","c\n","$\n",", and 0 otherwise\n","\n","\n","$\n","\\hat{y}_{i,c}\n","$\n","is the predicted probability for class \n","$\n","c\n","$\n","for sample \n","$\n","i\n","$\n","\n","\n","\n","$\n","C\n","$\n","is the number of classes and \n","$\n","n\n","$\n","is the number of samples.\n"]},{"cell_type":"code","execution_count":6,"id":"55235860","metadata":{"execution":{"iopub.execute_input":"2025-01-17T13:02:37.948553Z","iopub.status.busy":"2025-01-17T13:02:37.948058Z","iopub.status.idle":"2025-01-17T13:02:37.956542Z","shell.execute_reply":"2025-01-17T13:02:37.955489Z"},"papermill":{"duration":0.016991,"end_time":"2025-01-17T13:02:37.958734","exception":false,"start_time":"2025-01-17T13:02:37.941743","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["1.998401444325283e-15"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["def categorical_cross_entropy(y_true ,y_pred):\n","    y_pred = np.clip(y_pred , 1e-15,1-1e-15)\n","    return -np.sum(y_true * np.log(y_pred))/y_true.shape[0]\n","y_true= np.array([1,2,3])\n","y_pred = np.array([1,2,5])\n","categorical_cross_entropy(y_true,y_pred)\n","    \n"]},{"cell_type":"markdown","id":"f40c34c5","metadata":{"papermill":{"duration":0.005094,"end_time":"2025-01-17T13:02:37.969188","exception":false,"start_time":"2025-01-17T13:02:37.964094","status":"completed"},"tags":[]},"source":["### Sparse Categorical Cross Entropy"]},{"cell_type":"markdown","id":"beff9e1e","metadata":{"papermill":{"duration":0.004882,"end_time":"2025-01-17T13:02:37.979426","exception":false,"start_time":"2025-01-17T13:02:37.974544","status":"completed"},"tags":[]},"source":["$$\n","\\text{Sparse Categorical Crossentropy} = - \\frac{1}{n} \\sum_{i=1}^n \\log(\\hat{y}_{i, y_i})\n","$$\n","\n","where \n","$\n","y_i\n","$\n","is the true class index for sample \n","$\n","i\n","$\n",", \n","$\n","\\hat{y}_{i, y_i}\n","$\n","is the predicted probability for the true class of sample \n","$\n","i\n","$\n",", and \n","$\n","n\n","$\n","is the number of samples.\n"]},{"cell_type":"code","execution_count":7,"id":"f431f239","metadata":{"execution":{"iopub.execute_input":"2025-01-17T13:02:37.991817Z","iopub.status.busy":"2025-01-17T13:02:37.99143Z","iopub.status.idle":"2025-01-17T13:02:38.00226Z","shell.execute_reply":"2025-01-17T13:02:38.001127Z"},"papermill":{"duration":0.019499,"end_time":"2025-01-17T13:02:38.004303","exception":false,"start_time":"2025-01-17T13:02:37.984804","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["-0.164252033486018"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["def sparse_categorical_cross_entropy(y_true,y_pred):\n","    y_pred = np.clip(y_pred , 1e-15,1-1e-15)\n","    log_prob = -np.log(y_pred[np.arange(len(y_true)),y_true])\n","    return - np.mean(log_prob)\n","\n","y_true = np.array([1,0])\n","y_pred = np.array([[0.1,0.9,0.0],[0.8,0.2,0.0]])\n","sparse_categorical_cross_entropy(y_true,y_pred)\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":4.054108,"end_time":"2025-01-17T13:02:38.430865","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-01-17T13:02:34.376757","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}